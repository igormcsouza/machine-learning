{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequenceToSequence Model\n",
    "\n",
    "## Summary\n",
    "1. [Understanding a bit](#Understanding-a-bit)\n",
    "2. [Preparing the model](#Preparing-the-data-to-the-model)\n",
    "3. [Trainning the data](#Trainning-the-data)\n",
    "4. [Make Predictions](#Making-Predictions)\n",
    "\n",
    "...\n",
    "\n",
    "## Understanding a bit\n",
    "\n",
    "So far, we learned to use deep learning to build models to predict results from a previously amount of content. We used a special type of model named RNNs to make predictions given a set of data which depends on each other according to the time. We saw a Poetry Generation, that is a way to use RNNs to predic texts, to do so, we used Glove as Pre-Trained word vectors to transform word in numbers.\n",
    "\n",
    "Now we are going to see that, we can not only predict the sintax of the sentence, but we can use it to predict responses depending on that sintax we found.\n",
    "\n",
    "SeqToSeq is largerly used on machine translation and chatbot. SeqToSeq join together 2 RNNs, named encoder and decoder, one to find the sintax, and the other to transform the sintax back to a sentence, but in another esphere. It could be language to language, or question to answer.\n",
    "\n",
    "...\n",
    "\n",
    "### Where to find the data used here?\n",
    "1. Follow the [link](http://www.manythings.org/anki/) to find the data for translation on this notebook.\n",
    "2. Also, [GloVe](http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip) can be used for pre-trainned wordvectors\n",
    "\n",
    "### Find out More\n",
    "1. [How does SeqToSeq works - Towards Data Science](https://towardsdatascience.com/understanding-encoder-decoder-sequence-to-sequence-model-679e04af4346)\n",
    "2. [Attention - One Step Ahead - WildMl](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/?source=post_page---------------------------)\n",
    "\n",
    "### Mistakes fixed\n",
    "1. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Configurations is set here\n",
    "\n",
    "batch_size = 64 # Trainning set\n",
    "epochs = 100 # Times the model is going to repeat the steps\n",
    "latent_dim = 256 # Encoding space dimensionality\n",
    "num_samples = 10000 # Number of exemples\n",
    "max_sequence_length = 100\n",
    "max_num_words = 20000\n",
    "embedding_dim = 100 # Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place to store the data\n",
    "\n",
    "input_texts = [] # Original Language\n",
    "target_texts = [] # Target Language\n",
    "target_texts_inputs = [] # Same than the above but offset by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples:  10000\n"
     ]
    }
   ],
   "source": [
    "# Load in the data from manythings\n",
    "\n",
    "t = 0\n",
    "for line in open('../databases/large_files/translation/por.txt'):\n",
    "    # Limit the number of samples\n",
    "    '''\n",
    "    We know the input and the output needs to have the same size, so what we are\n",
    "    going to do is to pad every sample with the same length of the greates one. \n",
    "    If it is really big, there will be lots of wasted calculation for those how \n",
    "    are not so big. Keep the samples as shorest as possibe is a good way to go!\n",
    "    '''\n",
    "    t += 1\n",
    "    if t > num_samples:\n",
    "        break\n",
    "        \n",
    "    # Tab separate the input and the target\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "    \n",
    "    # Split them into 2 pieces\n",
    "    input_text, translation = line.split('\\t')\n",
    "    \n",
    "    # Using Teacher Forcing (https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/)\n",
    "    # Building the output and the input, introducing the tokens to them\n",
    "    target_text = translation + ' <eos>'\n",
    "    target_text_input = '<sos> ' + translation\n",
    "    \n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)\n",
    "print(\"Number of Samples: \", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2061 unique input tokens\n"
     ]
    }
   ],
   "source": [
    "# Tokenization step!\n",
    "\n",
    "# Inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=max_num_words)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# Index Mapping\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found {0} unique input tokens'.format(len(word2idx_inputs)))\n",
    "\n",
    "# Determine the Maximun Input Sequence Length\n",
    "max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4957 unique output tokens\n"
     ]
    }
   ],
   "source": [
    "# Outputs\n",
    "'''\n",
    "Be carreful to not filter special characteres, otherwise <sos> and \n",
    "<eos> will not appear!!\n",
    "'''\n",
    "tokenizer_outputs = Tokenizer(num_words=max_num_words, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient?\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs) \n",
    "\n",
    "# Index Mapping\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found {0} unique output tokens'.format(len(word2idx_outputs)))\n",
    "\n",
    "# Starts at 1 because of indexing\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# Determine the Maximun Input Sequence Length\n",
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enconder data shape: (10000, 5)\n",
      "Enconder data [0]: [ 0  0  0  0 24]\n",
      "Deconder data [0]: [   2 1390    0    0    0    0    0    0    0]\n",
      "Deconder data shape: (10000, 9)\n"
     ]
    }
   ],
   "source": [
    "# Pad Sequences\n",
    "\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"Enconder data shape: {0}\".format(encoder_inputs.shape))\n",
    "print(\"Enconder data [0]: {0}\".format(encoder_inputs[0]))\n",
    "      \n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "print(\"Deconder data [0]: {0}\".format(decoder_inputs[0]))\n",
    "print(\"Deconder data shape: {0}\".format(decoder_inputs.shape))\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "# Store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join(\n",
    "    '../databases/large_files/glove.6B/glove.6B.%sd.txt' % embedding_dim\n",
    ")) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "print('Found {0} word vectors'.format(len(word2vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Embedding Matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(max_num_words, len(word2idx_inputs)+1)\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < max_num_words:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Zeros if we can't find a word in Embedding\n",
    "            embedding_matrix[i] = embbeding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Layer\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_words,\n",
    "    embedding_dim,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=max_len_input,\n",
    "    # trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Once we cannot use sparce categorical cross entropy with sequences,\n",
    "let's now create the targets\n",
    "'''\n",
    "decoder_targets_one_hot = np.zeros((\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, assing the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = LSTM(latent_dim, return_state=True, dropout=0.5)\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "# encoder_outputs, h = encoder(x) # GRU?\n",
    "\n",
    "#States to pass to the decoder\n",
    "encoder_states = [h, c]\n",
    "# encoder_states = [state_h] # GRU\n",
    "\n",
    "# For the decoder, we are going to use [h, c] as initial state\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# Not using pre-trained word vectors\n",
    "decoder_embedding = Embedding(num_words_output, latent_dim)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "# The decoder is a to_many model, so we must set return_sequences=True\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.5)\n",
    "decoder_outputs, _, _ = decoder_lstm(\n",
    "    decoder_inputs_x,\n",
    "    initial_state=encoder_states\n",
    ")\n",
    "\n",
    "# decoder_outputs, _ = decoder_gru(\n",
    "#     decoder_inputs_x,\n",
    "#     initial_state=encoder_states\n",
    "# )\n",
    "\n",
    "# Dense layers for predictions\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder\n",
    "], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/souza/Documents/virtualenvs/datascience/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/souza/Documents/virtualenvs/datascience/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 36s 4ms/step - loss: 2.4838 - acc: 0.6633 - val_loss: 2.4560 - val_acc: 0.6447\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 1.9377 - acc: 0.7118 - val_loss: 2.3414 - val_acc: 0.6524\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 1.7795 - acc: 0.7237 - val_loss: 2.2207 - val_acc: 0.6653\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 1.6457 - acc: 0.7356 - val_loss: 2.0956 - val_acc: 0.6847\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 1.5376 - acc: 0.7477 - val_loss: 2.0233 - val_acc: 0.7003\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 1.4432 - acc: 0.7583 - val_loss: 1.9775 - val_acc: 0.7087\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 1.3616 - acc: 0.7671 - val_loss: 1.9697 - val_acc: 0.7136\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 1.2924 - acc: 0.7747 - val_loss: 1.9191 - val_acc: 0.7213\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 1.2357 - acc: 0.7815 - val_loss: 1.9200 - val_acc: 0.7258\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 1.1840 - acc: 0.7852 - val_loss: 1.9141 - val_acc: 0.7286\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 1.1376 - acc: 0.7916 - val_loss: 1.8982 - val_acc: 0.7286\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 39s 5ms/step - loss: 1.0985 - acc: 0.7958 - val_loss: 1.8817 - val_acc: 0.7294\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 1.0612 - acc: 0.7995 - val_loss: 1.8764 - val_acc: 0.7281\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 1.0255 - acc: 0.8040 - val_loss: 1.8829 - val_acc: 0.7324\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.9935 - acc: 0.8073 - val_loss: 1.8976 - val_acc: 0.7275\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.9626 - acc: 0.8130 - val_loss: 1.8970 - val_acc: 0.7286\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.9330 - acc: 0.8157 - val_loss: 1.8927 - val_acc: 0.7283\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.9069 - acc: 0.8191 - val_loss: 1.9017 - val_acc: 0.7276\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.8822 - acc: 0.8220 - val_loss: 1.9131 - val_acc: 0.7248\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.8608 - acc: 0.8263 - val_loss: 1.9120 - val_acc: 0.7267\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.8388 - acc: 0.8292 - val_loss: 1.9019 - val_acc: 0.7315\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.8167 - acc: 0.8317 - val_loss: 1.9169 - val_acc: 0.7282\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.7972 - acc: 0.8348 - val_loss: 1.9256 - val_acc: 0.7284\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.7784 - acc: 0.8379 - val_loss: 1.9364 - val_acc: 0.7291\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.7612 - acc: 0.8413 - val_loss: 1.9463 - val_acc: 0.7308\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.7453 - acc: 0.8431 - val_loss: 1.9526 - val_acc: 0.7287\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.7315 - acc: 0.8454 - val_loss: 1.9714 - val_acc: 0.7273\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.7169 - acc: 0.8483 - val_loss: 1.9795 - val_acc: 0.7245\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.7042 - acc: 0.8508 - val_loss: 2.0074 - val_acc: 0.7273\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.6892 - acc: 0.8523 - val_loss: 1.9980 - val_acc: 0.7268\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.6750 - acc: 0.8554 - val_loss: 2.0136 - val_acc: 0.7284\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.6597 - acc: 0.8565 - val_loss: 2.0249 - val_acc: 0.7274\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.6452 - acc: 0.8590 - val_loss: 2.0416 - val_acc: 0.7263\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.6327 - acc: 0.8613 - val_loss: 2.0157 - val_acc: 0.7282\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.6216 - acc: 0.8624 - val_loss: 2.0517 - val_acc: 0.7276\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.6099 - acc: 0.8638 - val_loss: 2.0531 - val_acc: 0.7273\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.5984 - acc: 0.8663 - val_loss: 2.0621 - val_acc: 0.7294\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.5870 - acc: 0.8674 - val_loss: 2.0586 - val_acc: 0.7288\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.5750 - acc: 0.8697 - val_loss: 2.0673 - val_acc: 0.7283\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.5643 - acc: 0.8723 - val_loss: 2.0978 - val_acc: 0.7277\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.5543 - acc: 0.8718 - val_loss: 2.0960 - val_acc: 0.7294\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 36s 4ms/step - loss: 0.5441 - acc: 0.8745 - val_loss: 2.1315 - val_acc: 0.7284\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.5337 - acc: 0.8751 - val_loss: 2.1148 - val_acc: 0.7305\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.5257 - acc: 0.8761 - val_loss: 2.1356 - val_acc: 0.7313\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 36s 4ms/step - loss: 0.5164 - acc: 0.8792 - val_loss: 2.1366 - val_acc: 0.7278\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.5089 - acc: 0.8800 - val_loss: 2.1371 - val_acc: 0.7317\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.5009 - acc: 0.8808 - val_loss: 2.1318 - val_acc: 0.7301\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.4947 - acc: 0.8827 - val_loss: 2.1471 - val_acc: 0.7296\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.4878 - acc: 0.8832 - val_loss: 2.1645 - val_acc: 0.7286\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.4815 - acc: 0.8857 - val_loss: 2.1788 - val_acc: 0.7294\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.4731 - acc: 0.8854 - val_loss: 2.1928 - val_acc: 0.7271\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.4650 - acc: 0.8879 - val_loss: 2.1927 - val_acc: 0.7292\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.4580 - acc: 0.8897 - val_loss: 2.1923 - val_acc: 0.7287\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.4501 - acc: 0.8908 - val_loss: 2.1858 - val_acc: 0.7294\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.4441 - acc: 0.8915 - val_loss: 2.2117 - val_acc: 0.7296\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.4382 - acc: 0.8928 - val_loss: 2.2037 - val_acc: 0.7298\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.4322 - acc: 0.8941 - val_loss: 2.2009 - val_acc: 0.7291\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.4248 - acc: 0.8949 - val_loss: 2.2213 - val_acc: 0.7278\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.4192 - acc: 0.8967 - val_loss: 2.2045 - val_acc: 0.7295\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.4132 - acc: 0.8969 - val_loss: 2.2405 - val_acc: 0.7296\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.4072 - acc: 0.8986 - val_loss: 2.2065 - val_acc: 0.7314\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.4019 - acc: 0.8989 - val_loss: 2.2213 - val_acc: 0.7327\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 0.3964 - acc: 0.9003 - val_loss: 2.2431 - val_acc: 0.7306\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 36s 5ms/step - loss: 0.3905 - acc: 0.9010 - val_loss: 2.2508 - val_acc: 0.7309\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3864 - acc: 0.9034 - val_loss: 2.2488 - val_acc: 0.7303\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3813 - acc: 0.9028 - val_loss: 2.2458 - val_acc: 0.7321\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3767 - acc: 0.9036 - val_loss: 2.2510 - val_acc: 0.7310\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3711 - acc: 0.9049 - val_loss: 2.2549 - val_acc: 0.7319\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3687 - acc: 0.9060 - val_loss: 2.2690 - val_acc: 0.7296\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 34s 4ms/step - loss: 0.3629 - acc: 0.9066 - val_loss: 2.2630 - val_acc: 0.7311\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3584 - acc: 0.9080 - val_loss: 2.2636 - val_acc: 0.7294\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3550 - acc: 0.9083 - val_loss: 2.2730 - val_acc: 0.7319\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 32s 4ms/step - loss: 0.3483 - acc: 0.9091 - val_loss: 2.2987 - val_acc: 0.7299\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 33s 4ms/step - loss: 0.3413 - acc: 0.9107 - val_loss: 2.2848 - val_acc: 0.7305\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 36s 4ms/step - loss: 0.3352 - acc: 0.9114 - val_loss: 2.2724 - val_acc: 0.7302\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.3301 - acc: 0.9123 - val_loss: 2.2972 - val_acc: 0.7301\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 35s 4ms/step - loss: 0.3271 - acc: 0.9123 - val_loss: 2.2747 - val_acc: 0.7295\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 36s 4ms/step - loss: 0.3222 - acc: 0.9130 - val_loss: 2.3109 - val_acc: 0.7307\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 0.3185 - acc: 0.9145 - val_loss: 2.3012 - val_acc: 0.7300\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 0.3163 - acc: 0.9142 - val_loss: 2.3168 - val_acc: 0.7301\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 0.3118 - acc: 0.9152 - val_loss: 2.3253 - val_acc: 0.7302\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 0.3083 - acc: 0.9167 - val_loss: 2.3241 - val_acc: 0.7319\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 45s 6ms/step - loss: 0.3054 - acc: 0.9167 - val_loss: 2.3135 - val_acc: 0.7314\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.3005 - acc: 0.9177 - val_loss: 2.3183 - val_acc: 0.7303\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2993 - acc: 0.9178 - val_loss: 2.3326 - val_acc: 0.7294\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2956 - acc: 0.9180 - val_loss: 2.3138 - val_acc: 0.7316\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2918 - acc: 0.9197 - val_loss: 2.3370 - val_acc: 0.7309\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2909 - acc: 0.9190 - val_loss: 2.3275 - val_acc: 0.7309\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2880 - acc: 0.9196 - val_loss: 2.3358 - val_acc: 0.7306\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2847 - acc: 0.9210 - val_loss: 2.3551 - val_acc: 0.7289\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2812 - acc: 0.9209 - val_loss: 2.3459 - val_acc: 0.7298\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2798 - acc: 0.9210 - val_loss: 2.3744 - val_acc: 0.7279\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 37s 5ms/step - loss: 0.2756 - acc: 0.9220 - val_loss: 2.3746 - val_acc: 0.7303\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2719 - acc: 0.9227 - val_loss: 2.3636 - val_acc: 0.7296\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2697 - acc: 0.9229 - val_loss: 2.3641 - val_acc: 0.7307\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2675 - acc: 0.9229 - val_loss: 2.3650 - val_acc: 0.7296\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2643 - acc: 0.9243 - val_loss: 2.3756 - val_acc: 0.7295\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2616 - acc: 0.9246 - val_loss: 2.3729 - val_acc: 0.7298\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2581 - acc: 0.9243 - val_loss: 2.3864 - val_acc: 0.7316\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 31s 4ms/step - loss: 0.2557 - acc: 0.9256 - val_loss: 2.3886 - val_acc: 0.7326\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "fit = model.fit(\n",
    "    [encoder_inputs, decoder_inputs],\n",
    "    decoder_targets_one_hot,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/souza/Documents/virtualenvs/datascience/lib/python3.7/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_4 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_3/while/Exit_3:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_3/while/Exit_4:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save to the disk at models/translation-eng-por.h5\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "model.save('../models/translation-eng-por.h5')\n",
    "print('Model save to the disk at models/translation-eng-por.h5')\n",
    "\n",
    "# # Load Model\n",
    "# from keras.models import load_model\n",
    "# model = load_model('../models/translation-eng-por.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
